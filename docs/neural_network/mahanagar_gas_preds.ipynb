{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A neural Network replacing the simple xgboost regression algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing all libraries and setting the device to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_percentage_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "# torch.cuda.set_device(\"cuda:0\")\n",
    "# print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def set_seeds(seed=1234):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # multi-GPU\n",
    "    \n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre processing the data and adding data indicators to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/mahanagar-gas/mahanagar_gas.csv\")\n",
    "# Need to reverse the db\n",
    "# df = df.loc[::-1]\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df[(df['Date'].dt.year >= 2020)].copy()\n",
    "df.index = range(len(df))\n",
    "temp = df\n",
    "# df['Close'] = (df['High'] + df['Low'] )/ 2\n",
    "df.rename(columns={\"Open Price\":\"Open\",\"High Price\":\"High\",\"Low Price\":\"Low\",\"Close Price\":\"Close\",\"Total Traded Quantity\":\"Volume\",\"No.of Shares\":\"Volume\",\"Price\":\"Close\"},inplace=True)\n",
    "# cols = [\"Symbol\",\"Ser verbose=Falseies\",\"Prev Close\",\"Last Price\",\"Average Price\",\"Turnover\",\"No. of Trades\", \"Deliverable Qty\",'% Dly Qt to Traded Qty']\n",
    "# cols = [\"WAP\",\"No. of Trades\"\t,\"Total Turnover (Rs.)\"\t,\"Deliverable Quantity\"\t,\"% Deli. Qty to Traded Qty\"\t,\"Spread High-Low\"\t,\"Spread Close-Open\"]\n",
    "# cols = \"Adj Close\"\n",
    "cols = \"Change(%)\"\n",
    "df.drop(columns=cols,inplace=True)   \n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EMA_9'] = df['Close'].ewm(9).mean().shift()\n",
    "df['SMA_5'] = df['Close'].rolling(5).mean().shift()\n",
    "df['SMA_10'] = df['Close'].rolling(10).mean().shift()\n",
    "df['SMA_15'] = df['Close'].rolling(15).mean().shift()\n",
    "df['SMA_30'] = df['Close'].rolling(30).mean().shift()\n",
    "\n",
    "def relative_strength_idx(df, n=14):\n",
    "    close = df['Close']\n",
    "    delta = close.diff()\n",
    "    delta = delta[1:]\n",
    "    pricesUp = delta.copy()\n",
    "    pricesDown = delta.copy()\n",
    "    pricesUp[pricesUp < 0] = 0\n",
    "    pricesDown[pricesDown > 0] = 0    \n",
    "    rollUp = pricesUp.rolling(n).mean()\n",
    "    rollDown = pricesDown.abs().rolling(n).mean()\n",
    "    rs = rollUp / rollDown\n",
    "    rsi = 100.0 - (100.0 / (1.0 + rs))\n",
    "    return rsi\n",
    "\n",
    "df['RSI'] = relative_strength_idx(df).fillna(0)\n",
    "\n",
    "EMA_12 = pd.Series(df['Close'].ewm(span=12, min_periods=12).mean())\n",
    "EMA_26 = pd.Series(df['Close'].ewm(span=26, min_periods=26).mean())\n",
    "df['MACD'] = pd.Series(EMA_12 - EMA_26)\n",
    "df['MACD_signal'] = pd.Series(df.MACD.ewm(span=9, min_periods=9).mean())\n",
    "\n",
    "df['Close'] = df['Close'].shift(-1)\n",
    "\n",
    "df = df.iloc[33:] # Because of moving average\n",
    "df = df[:-1]      # Because of shifting close price\n",
    "\n",
    "df.index = range(len(df))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Date', 'Volume', 'Open', 'Low', 'High']\n",
    "df.drop(columns=drop_cols,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating the data into train and test splits. Then splitting into validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 1]\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialising the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RegressionDataset(\n",
    "    torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float()\n",
    ")\n",
    "val_dataset = RegressionDataset(\n",
    "    torch.from_numpy(X_val).float(), torch.from_numpy(y_val).float()\n",
    ")\n",
    "test_dataset = RegressionDataset(\n",
    "    torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1800\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_FEATURES = len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE,)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleRegression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(MultipleRegression, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(num_features, 16)\n",
    "        self.layer_2 = nn.Linear(16, 32)\n",
    "        self.layer_3 = nn.Linear(32, 16)\n",
    "        self.layer_out = nn.Linear(16, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, test_inputs):\n",
    "        x = self.relu(self.layer_1(test_inputs))\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.relu(self.layer_3(x))\n",
    "        x = self.layer_out(x)\n",
    "        return x\n",
    "# torch.cuda.set_device(\"cuda:0\")\n",
    "# print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "model = MultipleRegression(NUM_FEATURES)\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in tqdm(range(1, EPOCHS + 1)):\n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    model.train()\n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(\n",
    "            device\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_train_pred = model(X_train_batch)\n",
    "\n",
    "        train_loss = criterion(y_train_pred, y_train_batch.unsqueeze(1))\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_epoch_loss += train_loss.item()\n",
    "\n",
    "    # VALIDATION\n",
    "    with torch.no_grad():\n",
    "        val_epoch_loss = 0\n",
    "\n",
    "        model.eval()\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "\n",
    "            y_val_pred = model(X_val_batch)\n",
    "\n",
    "            val_loss = criterion(y_val_pred, y_val_batch.unsqueeze(1))\n",
    "\n",
    "            val_epoch_loss += val_loss.item()\n",
    "        # print(torch.cuda.get_device_name())\n",
    "\n",
    "        loss_stats[\"train\"].append(train_epoch_loss / len(train_loader))\n",
    "        loss_stats[\"val\"].append(val_epoch_loss / len(val_loader))\n",
    "\n",
    "    if e % 50 == 0:\n",
    "        print(\n",
    "            f\"Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f}\"\n",
    "        )\n",
    "# torch.cuda.set_device(\"cuda:0\")\n",
    "# print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(loss_stats['train']))\n",
    "print(len(loss_stats['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loss_df = (\n",
    "    pd.DataFrame.from_dict(loss_stats)\n",
    "    .reset_index()\n",
    "    .melt(id_vars=[\"index\"])\n",
    "    .rename(columns={\"index\": \"epochs\"})\n",
    ")\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.lineplot(data=train_val_loss_df, x=\"epochs\", y=\"value\", hue=\"variable\").set_title(\n",
    "    \"Train-Val Loss/Epoch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for X_batch, _ in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_pred_list.append(y_test_pred.cpu().numpy())\n",
    "        y_pred_list = [a for a in y_pred_list]\n",
    "        \n",
    "y_pred = []\n",
    "for i in tqdm(range(len(y_pred_list))):\n",
    "    for j in range(len(y_pred_list[i])):\n",
    "        for k in range(len(y_pred_list[i][j])):\n",
    "            y_pred.append(y_pred_list[i][j][k])\n",
    "\n",
    "print(y_pred)  \n",
    "print(y_test.tolist())\n",
    "y_pred_np = np.array(y_pred)\n",
    "difference = np.subtract(y_pred_np, y_test)\n",
    "difference = abs(difference)\n",
    "mean_difference = np.mean(difference)\n",
    "print(f\"The average deviation in error is: {mean_difference}\")\n",
    "sns.lineplot(difference).set(title=\"Deviation of Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_square = r2_score(y_test, y_pred)\n",
    "mean_abs_err = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error :\",mse)\n",
    "print(\"R^2 :\",r_square)\n",
    "print(f\"Accuracy (using MSE): {(100 - mse)}%\")\n",
    "print(f\"Mean absolute percentage error: {100 - mean_abs_err}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as py\n",
    "import plotly.io as pio    \n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=3, cols=1)\n",
    "fig.add_trace(go.Scatter(x=temp.index // 15, y=df.Close,\n",
    "                         name='Truth',\n",
    "                         marker_color='LightSkyBlue'), row=1, col=1)\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=(len(temp) // 15 + (temp.index // 15)),\n",
    "                         y=y_pred,\n",
    "                         name='Prediction',\n",
    "                         marker_color='MediumPurple'), row=2, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=(len(temp) // 15 + (temp.index // 15)),\n",
    "                         y=y_test,\n",
    "                         name='Truth',\n",
    "                         marker_color='LightSkyBlue',\n",
    "                         showlegend=False), row=3, col=1)\n",
    "\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
